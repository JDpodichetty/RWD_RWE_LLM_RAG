{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a60c1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üöÄ Starting PDF Cleaning Process for RAG ---\n",
      "Found 13 PDF(s) to process.\n",
      "Processing: Full article_ Acute otitis media.pdf...\n",
      "  -> Saved cleaned text to: Full article_ Acute otitis media.txt\n",
      "Processing: Earwax build-up - NHS.pdf...\n",
      "  -> Saved cleaned text to: Earwax build-up - NHS.txt\n",
      "Processing: Etiology, Diagnosis, Complications, and Management of Acute Otitis Media in Children - PMC.pdf...\n",
      "  -> Saved cleaned text to: Etiology, Diagnosis, Complications, and Management of Acute Otitis Media in Children - PMC.txt\n",
      "Processing: Chronic otitis media - ScienceDirect.pdf...\n",
      "  -> Saved cleaned text to: Chronic otitis media - ScienceDirect.txt\n",
      "Processing: Tympanosclerosis (Myringosclerosis) _ Doctor.pdf...\n",
      "  -> Saved cleaned text to: Tympanosclerosis (Myringosclerosis) _ Doctor.txt\n",
      "Processing: Chronic Otitis Media, Cholesteatoma and Mastoiditis - Harvard Health.pdf...\n",
      "  -> Saved cleaned text to: Chronic Otitis Media, Cholesteatoma and Mastoiditis - Harvard Health.txt\n",
      "Processing: Chronic Suppurative Otitis - StatPearls - NCBI Bookshelf.pdf...\n",
      "  -> Saved cleaned text to: Chronic Suppurative Otitis - StatPearls - NCBI Bookshelf.txt\n",
      "Processing: What Is Myringosclerosis_.pdf...\n",
      "  -> Saved cleaned text to: What Is Myringosclerosis_.txt\n",
      "Processing: Ear wax - symptoms, causes and treatment _ healthdirect.pdf...\n",
      "  -> Saved cleaned text to: Ear wax - symptoms, causes and treatment _ healthdirect.txt\n",
      "Processing: Chronic Otitis Media.pdf...\n",
      "  - Page 84 seems scanned. Applying OCR...\n",
      "  -> Saved cleaned text to: Chronic Otitis Media.txt\n",
      "Processing: Ear wax_ MedlinePlus Medical Encyclopedia.pdf...\n",
      "  -> Saved cleaned text to: Ear wax_ MedlinePlus Medical Encyclopedia.txt\n",
      "Processing: Myringosclerosis - an overview _ ScienceDirect Topics.pdf...\n",
      "  -> Saved cleaned text to: Myringosclerosis - an overview _ ScienceDirect Topics.txt\n",
      "Processing: Acute Otitis Media - StatPearls - NCBI Bookshelf.pdf...\n",
      "  -> Saved cleaned text to: Acute Otitis Media - StatPearls - NCBI Bookshelf.txt\n",
      "\n",
      "--- ‚úÖ PDF Cleaning Process Finished! ---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "# 1. DEFINE YOUR FOLDER PATHS\n",
    "#    Replace these with the actual paths on your system.\n",
    "INPUT_FOLDER = \"Documents\"\n",
    "OUTPUT_FOLDER = \"Documents_Cleaned\"\n",
    "\n",
    "# 2. TESSERACT OCR INSTALLATION (IMPORTANT!)\n",
    "#    This script requires Google's Tesseract OCR engine to be installed on your system.\n",
    "#    - Windows: Download and run the installer from https://github.com/UB-Mannheim/tesseract/wiki\n",
    "#      During installation, make sure to note the installation path.\n",
    "#    - macOS: `brew install tesseract`\n",
    "#    - Linux (Ubuntu/Debian): `sudo apt-get install tesseract-ocr`\n",
    "#\n",
    "#    After installing, you might need to tell pytesseract where to find it.\n",
    "#    Uncomment the line below and set the path if you get a \"TesseractNotFoundError\".\n",
    "#    pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe' # Example for Windows\n",
    "#    pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract' # Example for Linux\n",
    "\n",
    "# 3. OCR HEURISTIC\n",
    "#    If a page has fewer than this many text characters extracted directly,\n",
    "#    we'll assume it's a scanned image and apply OCR.\n",
    "OCR_THRESHOLD = 50\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Applies a series of cleaning steps to the extracted text to remove\n",
    "    common noise like URLs, references, dates, times, and formatting artifacts.\n",
    "    \n",
    "    Args:\n",
    "        text: The raw text extracted from a PDF page.\n",
    "        \n",
    "    Returns:\n",
    "        Cleaned text ready for RAG ingestion.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "\n",
    "    # 1. Discard content after \"References\" or \"Bibliography\" headings\n",
    "    #    This is a strong heuristic for academic papers.\n",
    "    text = re.split(r'\\n\\s*(?:references|bibliography)\\s*\\n', text, flags=re.IGNORECASE)[0]\n",
    "\n",
    "    # 2. Remove URLs and email addresses\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '', text)\n",
    "\n",
    "    # 3. Remove common academic paper identifiers (e.g., arXiv, DOI)\n",
    "    text = re.sub(r'arXiv:\\S+', '', text)\n",
    "    text = re.sub(r'doi:\\S+', '', text)\n",
    "\n",
    "    # 4. Remove dates and times üìÖ\n",
    "    #    Matches formats like \"August 3, 2025\", \"3 Aug 2025\", \"2025-08-03\", \"03/08/2025\"\n",
    "    month_names = r'(?:January|February|March|April|May|June|July|August|September|October|November|December|Jan|Feb|Mar|Apr|Jun|Jul|Aug|Sep|Oct|Nov|Dec)'\n",
    "    text = re.sub(fr'\\b(?:\\w+day,\\s)?(?:\\d{{1,2}}\\s)?{month_names}\\s\\d{{1,2}},?\\s\\d{{4}}\\b', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\b\\d{1,4}[-/]\\d{1,2}[-/]\\d{1,4}\\b', '', text)\n",
    "    #    Matches formats like \"6:19 PM\", \"18:19:34\", \"6:19 PM IST\"\n",
    "    text = re.sub(r'\\b\\d{1,2}:\\d{2}(?::\\d{2})?\\s*(?:AM|PM|IST|GMT|UTC)?\\b', '', text, flags=re.IGNORECASE)\n",
    "\n",
    "    # 5. Remove in-text citations, e.g., [1], [2, 3], [4-7]\n",
    "    text = re.sub(r'\\[\\d+(?:, ?\\d+)*(?:-\\d+)?\\]', '', text)\n",
    "\n",
    "    # 6. Fix hyphenated words that are broken across lines\n",
    "    text = re.sub(r'(\\w+)-\\n(\\w+)', r'\\1\\2', text)\n",
    "\n",
    "    # 7. Remove isolated newlines to join paragraphs\n",
    "    text = re.sub(r'(?<!\\n)\\n(?!\\n)', ' ', text)\n",
    "\n",
    "    # 8. Remove figure/table captions (e.g., \"Figure 1: ...\", \"Table 2. ...\")\n",
    "    text = re.sub(r'\\n\\s*(?:Figure|Table) \\d+[:.].*?\\n', '\\n', text, flags=re.IGNORECASE)\n",
    "\n",
    "    # 9. Replace multiple spaces with a single space\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "\n",
    "    # 10. Replace multiple newlines with a single newline to fix paragraph spacing\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    \n",
    "    # 11. Remove common headers/footers (e.g., page numbers)\n",
    "    #     This regex removes lines that look like \"Page 5 of 12\" or just a number\n",
    "    text = re.sub(r'\\n\\s*Page \\d+(?: of \\d+)?\\s*\\n', '\\n', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\n\\s*\\d+\\s*\\n', '\\n', text) # Removes lines containing only a number\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def process_pdf(pdf_path: str, output_path: str):\n",
    "    \"\"\"\n",
    "    Processes a single PDF file, extracts and cleans its text, and saves it.\n",
    "    It automatically decides whether to use standard text extraction or OCR.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: The full path to the input PDF file.\n",
    "        output_path: The full path where the cleaned .txt file will be saved.\n",
    "    \"\"\"\n",
    "    print(f\"Processing: {os.path.basename(pdf_path)}...\")\n",
    "    \n",
    "    full_text = \"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        \n",
    "        for page_num, page in enumerate(doc):\n",
    "            # First, try standard text extraction\n",
    "            page_text = page.get_text(\"text\")\n",
    "            \n",
    "            # If the text is short, it might be a scanned image. Use OCR.\n",
    "            if len(page_text.strip()) < OCR_THRESHOLD:\n",
    "                print(f\"  - Page {page_num + 1} seems scanned. Applying OCR...\")\n",
    "                try:\n",
    "                    # Render page to an image with higher DPI for better OCR quality\n",
    "                    pix = page.get_pixmap(dpi=300) \n",
    "                    img_data = pix.tobytes(\"png\")\n",
    "                    image = Image.open(io.BytesIO(img_data))\n",
    "                    \n",
    "                    # Use Tesseract to extract text from the image\n",
    "                    ocr_text = pytesseract.image_to_string(image, lang='eng')\n",
    "                    page_text = ocr_text\n",
    "                except Exception as ocr_error:\n",
    "                    print(f\"    - OCR failed for page {page_num + 1}: {ocr_error}\")\n",
    "                    page_text = \"\" # Skip page on OCR error\n",
    "            \n",
    "            full_text += page_text + \"\\n\\n\" # Add space between pages\n",
    "            \n",
    "        doc.close()\n",
    "\n",
    "        # Clean the aggregated text from all pages at once\n",
    "        cleaned_full_text = clean_text(full_text)\n",
    "        \n",
    "        # Save the final cleaned text to a file\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(cleaned_full_text)\n",
    "            \n",
    "        print(f\"  -> Saved cleaned text to: {os.path.basename(output_path)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  -> ERROR processing {os.path.basename(pdf_path)}: {e}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the PDF cleaning pipeline.\n",
    "    \"\"\"\n",
    "    print(\"--- üöÄ Starting PDF Cleaning Process for RAG ---\")\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(OUTPUT_FOLDER):\n",
    "        os.makedirs(OUTPUT_FOLDER)\n",
    "        print(f\"Created output directory: {OUTPUT_FOLDER}\")\n",
    "        \n",
    "    # Check if input directory exists\n",
    "    if not os.path.exists(INPUT_FOLDER):\n",
    "        print(f\"‚ùå ERROR: Input directory not found: {INPUT_FOLDER}\")\n",
    "        # Create a dummy source folder for the user\n",
    "        os.makedirs(INPUT_FOLDER)\n",
    "        print(f\"Created a sample input directory. Please add your PDFs to '{INPUT_FOLDER}'.\")\n",
    "        return\n",
    "\n",
    "    # Get a list of all PDF files in the input folder\n",
    "    pdf_files = [f for f in os.listdir(INPUT_FOLDER) if f.lower().endswith(\".pdf\")]\n",
    "    \n",
    "    if not pdf_files:\n",
    "        print(f\"No PDF files found in '{INPUT_FOLDER}'.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(pdf_files)} PDF(s) to process.\")\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        input_pdf_path = os.path.join(INPUT_FOLDER, pdf_file)\n",
    "        # Create a corresponding .txt filename for the output\n",
    "        output_txt_filename = os.path.splitext(pdf_file)[0] + \".txt\"\n",
    "        output_txt_path = os.path.join(OUTPUT_FOLDER, output_txt_filename)\n",
    "        \n",
    "        process_pdf(input_pdf_path, output_txt_path)\n",
    "        \n",
    "    print(\"\\n--- ‚úÖ PDF Cleaning Process Finished! ---\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c052b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
